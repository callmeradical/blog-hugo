<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lars Cromley</title>
    <link>https://callmeradical.com/</link>
    <description>Recent content on Lars Cromley</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>&amp;copy; &lt;a href=&#34;https://github.com/callmeradical&#34;&gt;Lars Cromley&lt;/a&gt; 2016</copyright>
    <lastBuildDate>Tue, 15 Nov 2016 21:10:46 -0500</lastBuildDate>
    <atom:link href="https://callmeradical.com/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>AWS API Gateway w/ Kubernetes ingress map</title>
      <link>https://callmeradical.com/post/aws-api-gateway-kubernetes/</link>
      <pubDate>Tue, 15 Nov 2016 21:10:46 -0500</pubDate>
      
      <guid>https://callmeradical.com/post/aws-api-gateway-kubernetes/</guid>
      <description>&lt;p&gt;Working on large scale unified APIs seems to be a popular trend. Recently I was working with
Microsoft&amp;rsquo;s Graph API, which is their unified API. It is not unreasonable to think that many
different teams contribute to the different resources available; mail, calendars, contacts,
directories. However many resources, the idea is to have all of them referenced from the same
endpoint.&lt;/p&gt;

&lt;p&gt;Ideally each team could use whatever language, whatever technology best worked for them. AWS API
Gateway fullfills that easily.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: This post makes the assumption that you have a functional Kubernetes cluster&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;First we are going to create a new api in Service Gateway.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ aws apigateway create-rest-api --name demo
$ export API_ID=&amp;lt;created api id&amp;gt;
$ aws apigateway get-resources --rest-api-id=$API_ID
$ export PARENT_ID=&amp;lt;resource id&amp;gt;
$ aws apigateway create-resource \
	--rest-api-id=$API_ID \
	--parent-id=$PARENT_ID \
	--path-part=&amp;quot;health&amp;quot;
$ export HEALTH_ID=&amp;lt;resource id&amp;gt;
$ aws apigateway put-method \
	--rest-api-id=$API_ID \
	--resource-id $HEALTH_ID \
	--http-method GET \
	--authorization-type NONE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We are going to stop with the API gateway for now, but we will come back to it.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s take a look at the app we are going to be running.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/callmeradical/healthy&#34;&gt;Source Code @ Github&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;package main

import (
	&amp;quot;encoding/json&amp;quot;
	&amp;quot;log&amp;quot;	
	&amp;quot;net/http&amp;quot;
)

type Response struct {
	Version	string `json:&amp;quot;version&amp;quot;`
	Message string `json:&amp;quot;message&amp;quot;`
}

func healthz(w http.ResponseWriter, r *http.Request) {
	res := Response{
		Version: &amp;quot;v1.0&amp;quot;,
		Message: &amp;quot;We are Healthy!&amp;quot;,
 	}

	str, err := json.MarshalIndent(&amp;amp;res, &amp;quot;&amp;quot;, &amp;quot;\t&amp;quot;)
	if err != nil {
		log.Println(err.Error())
	}

	w.Write(string(str))
}

func main() {
	http.HandleFunc(&amp;quot;/health&amp;quot;, healthz)
	err := http.ListenAndServe(&amp;quot;:8080&amp;quot;, nil)
	if err != nil {
		log.Fatal(&amp;quot;ListenAndServe: &amp;quot;, err)
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The app we are going to use is a restful application that responds to a GET on the /health endpoint
on port 8080 and prints &amp;ldquo;We are healthy!&amp;rdquo;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-yaml&#34;&gt;apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  labels:
    app: healthy
  name: healthy
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: healthy
      name: healthy
    spec:
      containers:
        - name: healthy
          image: &amp;quot;callmeradical/healthy:1.0.0&amp;quot;
---
apiVersion: v1
kind: Service
metadata:
  name: healthy-app
  labels:
    app: healthy
spec:
  ports:
    - port: 80
      targetPort: 8080
  selector:
    app: healthy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So now this little snippet of yaml will create a deployment in kubernetes and
expose it. Let&amp;rsquo;s go ahead and deploy our app. While we are at it we can verify our
app is in fact actually running and serving traffic.&lt;/p&gt;

&lt;p&gt;From the root of the cloned project:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ kubectl create -f kubernetes/healthy-deployment-svc.yml
$ kubectl get pods
$ kubectl port-forward &amp;lt;name of pod here&amp;gt; 8080:8080
$ curl localhost:8080/health
{
	&amp;quot;version&amp;quot;: &amp;quot;v1.0&amp;quot;,
	&amp;quot;message&amp;quot;: &amp;quot;We are Healthy!&amp;quot;

}
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;A Deployment provides declarative updates for Pods and Replica Sets (the next-generation
Replication Controller). You only need to describe the desired state in a Deployment object,
and the Deployment controller will change the actual state to the desired state at a
controlled rate for you. You can define Deployments to create new resources,
or replace existing ones by new ones.&lt;/p&gt;

&lt;p&gt;&amp;ndash; Kubernetes Documentation @ (&lt;a href=&#34;http://kubernetes.io/docs/user-guide/deployments/#what-is-a-deployment&#34;&gt;http://kubernetes.io/docs/user-guide/deployments/#what-is-a-deployment&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now we have our app, a skeleton for API Gateway, but we aren&amp;rsquo;t quite done. We still need to create our
ingress map, our nginx controller, and finish creating the API gateway. Let&amp;rsquo;s start working on deploying
the ingress controller. An ingress controller is a daemon that is deployed as a kubernetes pod. That pod
watches the API server&amp;rsquo;s /ingresses endpoint for updates to the ingress resource. Its job is to satisfy
requests for ingress.&lt;/p&gt;

&lt;p&gt;We aren&amp;rsquo;t going to write our controller, as that is out of the scope of this post, but we are going to use
the example controller used on the Kubernetes site, the nginx controller. The nginx controller does the following:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Poll until apiserver reports a new ingress&lt;/li&gt;
&lt;li&gt;write the nginx config file based on a go text/template&lt;/li&gt;
&lt;li&gt;Reload nginx&lt;/li&gt;
&lt;/ul&gt;

&lt;ol&gt;
&lt;li&gt;Describe Kubernetes ingress map&lt;/li&gt;
&lt;li&gt;Create Ingress Nginx/Controller&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Raft for Dummies and those like me.</title>
      <link>https://callmeradical.com/post/raft-for-dummies/</link>
      <pubDate>Sun, 11 Sep 2016 19:28:49 -0500</pubDate>
      
      <guid>https://callmeradical.com/post/raft-for-dummies/</guid>
      <description>

&lt;p&gt;This is going to be my very feeble attempt to explain the Raft consensus algorithm.  The very least I will accomplish is sharing the material I have read about Raft and how I have come to understand it. Raft is used in popular pieces of software such as RethinkDB, etcd, and a number of Hashicorp products.(&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:1&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:1&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;)&lt;/p&gt;

&lt;h3 id=&#34;what-is-raft&#34;&gt;What is Raft?&lt;/h3&gt;

&lt;p&gt;Raft was developed in the hopes of creating an easy to understand consensus algorithm. As far as that goes, I think they succeeded, especially when compared with similiar algorithms, such as &lt;a href=&#34;https://en.wikipedia.org/wiki/Paxos_(computer_science)&#34;&gt;Paxos&lt;/a&gt;(I am still working this one out). Consensus algorithms allow a collection of machines to work as a coherent group that can survive the failures of some of its members.(&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:2&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:2&#34;&gt;2&lt;/a&gt;&lt;/sup&gt;)&lt;/p&gt;

&lt;p&gt;To really understand this, lets take a step back and talk about what makes up a distributed system. Wikipedia has a really great definition on the &lt;a href=&#34;https://en.wikipedia.org/wiki/Distributed_computing&#34;&gt;Distributed Computing page&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;A distributed system is a model in which components located on networked computers communicate and coordinate their actions by passing messages.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The consensus algorithm is how these computers coordinate their actions. Implementing a consensus algorithm is typically necessary in the context of &lt;em&gt;replicated state machines&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;A common implementation of a replicated state machine, uses a replicated log. In otherwords, the following is true:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Multiple logs containing a series of commands or transactions.&lt;/li&gt;
&lt;li&gt;Each log must contain the same instructions in the same order.&lt;/li&gt;
&lt;li&gt;Each machine processes the same sequence of commands.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A commonplace example of this, at least in most enterprise shops, is Zookeeper. Zookeeper is an example of a replicated state machine.&lt;img src=&#34;https://dl.dropboxusercontent.com/s/eahsi12m5jov22u/statemachine.png&#34; alt=&#34;cloudcraft - RSM (1)&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This is the basic design of state machine architecture. Client sends a message to the consensus module, the consensus module replicates the transaction to multiple logs, the state machine reads from the logs and returns the value or transaction back to the client.&lt;/p&gt;

&lt;p&gt;The log is very important. The consensus algorithm is the manner in which we keep the replicated log consistent. The consensus module on a node receives instructions from clients, adds them to its log, and it communicates to other servers to ensure that every log eventually contains all requests in the in which they were received, even if some servers fail. After the commands are properly replicated, each server&amp;rsquo;s state machine processes them in log order, and output is returned to the client nodes. The outcome, is a system that appears to be a single, highly reliable, state machine. This is true with the exception of Byzantine conditions(&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:3&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:3&#34;&gt;3&lt;/a&gt;&lt;/sup&gt;) (network delays, partitions, packet loss, duplication, and reordering).&lt;/p&gt;

&lt;p&gt;In Raft a node can be in 1 of 3 states:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The Follower state&lt;/li&gt;
&lt;li&gt;The Candidate state&lt;/li&gt;
&lt;li&gt;The Leader state&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All nodes start in the follower state. If Followers don&amp;rsquo;t hear from a leader then they can become a candidate. The candidate then requests votes from other nodes. Nodes reply with their vote. The candidate becomes the leader if it gets votes from a majority of nodes. This is the process called &lt;em&gt;Leader Election&lt;/em&gt;. All changes now flow through the leader. Each change is added as an entry in the node&amp;rsquo;s log. The log entry is uncommitted and as such will not update the node&amp;rsquo;s value, instead, the node first replicates it to the follower nodes, then the leader waits until a majority of nodes have written the entry, and is then committed to the leader node. The leader then notifies the followers that the entry is committed. The cluster has then come to a consensus. This is log replication.&lt;/p&gt;

&lt;p&gt;Leader Election&lt;/p&gt;

&lt;p&gt;In Raft there are two timeout settings which control elections, &lt;em&gt;Election Timeout&lt;/em&gt;, and &lt;em&gt;Heartbeat Timeout&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Election timeout is the amount of time a follower waits until becoming a candidate. Election timeout is randomized to be between 150 ms and 300 ms. After the election timeout the follower becomes a candidate and starts a new election term, votes for itself, and sends out Request Vote messages to other nodes. If the receiving node hasn&amp;rsquo;t voted yet in this term then it votes for the candidate, and the node resets its election timeout. Once a candidate has a majority of votes it becomes leader.&lt;/p&gt;

&lt;p&gt;The leader begins sending out Append Entries messages to its followers. These messages are sent in intervals specified by the heartbeat timeout. Followers then respond to each Append Entries message. This election term will continue until a follower stops receiving heartbeats and becomes a candidate. Requiring a majority of votes guarantees that only one leader can be elected per term. If two nodes become candidates at the same time then a split vote can occur. In the event of a split vote, say we had four nodes, two nodes both start an election for the same term, and each reaches a single follower node before the other. Now each candidate has 2 votes and can receive no more for this term. The nodes will wait for a new election and try again. This will continue until majority is reached.(&lt;sup class=&#34;footnote-ref&#34; id=&#34;fnref:4&#34;&gt;&lt;a rel=&#34;footnote&#34; href=&#34;#fn:4&#34;&gt;4&lt;/a&gt;&lt;/sup&gt;)&lt;/p&gt;

&lt;p&gt;Raft was created to be easier to understand than Paxos. There is a conference specifically for systems design called the NSDI (Networked Systems Design and Implementation) and someone there even voiced concern about people understanding all components of Paxos. Claiming that there only 5 people are the conference that understood it completely. Whether or not that is true. I can say for sure, Raft is definitely easier to understand and has succeeded in that mission.&lt;/p&gt;

&lt;h3 id=&#34;references&#34;&gt;References&lt;/h3&gt;
&lt;div class=&#34;footnotes&#34;&gt;

&lt;hr /&gt;

&lt;ol&gt;
&lt;li id=&#34;fn:1&#34;&gt;&lt;a href=&#34;https://raft.github.io/#implementations&#34;&gt;Raft Implementations&lt;/a&gt; |
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:1&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:2&#34;&gt;&lt;a href=&#34;https://raft.github.io/raft.pdf&#34;&gt;In Search of an Understandable Consesus Algorithm &lt;/a&gt; |
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:2&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:3&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Byzantine_fault_tolerance&#34;&gt;Byzantine fault tolerance&lt;/a&gt; |
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:3&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li id=&#34;fn:4&#34;&gt;&lt;a href=&#34;http://thesecretlivesofdata.com/raft/#home&#34;&gt;The Secret Lift of Data - Raft&lt;/a&gt; |
 &lt;a class=&#34;footnote-return&#34; href=&#34;#fnref:4&#34;&gt;&lt;sup&gt;[return]&lt;/sup&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Using Consul with Registrator</title>
      <link>https://callmeradical.com/post/using-consul-with-registrator/</link>
      <pubDate>Sat, 10 Sep 2016 15:03:44 -0700</pubDate>
      
      <guid>https://callmeradical.com/post/using-consul-with-registrator/</guid>
      <description>&lt;p&gt;Service discovery is not new, but I still see plenty of shops storing their configuration in the form of configuration files or hardcoded objects. Connecting to an instance of MySQL or Redis and hard coding connection strings beforehand doesn&amp;rsquo;t allow one to take full advantage of dynamic resources and also doesn&amp;rsquo;t allow for treating them as backing resources.&lt;/p&gt;

&lt;p&gt;We are going to take a quick walk through setting up a &lt;a href=&#34;consul.io&#34;&gt;consul&lt;/a&gt; cluster using docker-machine and have &lt;a href=&#34;http://gliderlabs.com/registrator/latest/&#34;&gt;registrator&lt;/a&gt; dynamically create entries in consul&amp;rsquo;s service catalog. This post goes on the assumption that you have the Docker toolkit installed/configured with VirtualBox and some working knowledge of docker in general.&lt;/p&gt;

&lt;p&gt;The first thing we need to do is get some instances to play with.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker-machine create --driver virtualbox dev1
$ docker-machine create --driver virtualbox dev2
$ docker-machine create --driver virtualbox dev3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Once our machines are up and running we can then connect the Docker service by running:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker-machine env &amp;lt;boxid&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You will see some output similar to this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export DOCKER_TLS_VERIFY=&amp;quot;1&amp;quot;
export DOCKER_HOST=&amp;quot;tcp://192.168.99.100:2376&amp;quot;
export DOCKER_CERT_PATH=&amp;quot;/Users/demo/.docker/machine/machines/dev1&amp;quot;
export DOCKER_MACHINE_NAME=&amp;quot;dev1&amp;quot;
# Run this command to configure your shell: 
# eval $(docker-machine env dev1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we have our shell configured for the first host we are going to work on. The last piece of information we will need before we can begin launching our consul service is the IP addresses of the machines or nodes.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker-machine ls
NAME   ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER    ERRORS
dev1   -        virtualbox   Running   tcp://192.168.99.100:2376           v1.12.1   
dev2   -        virtualbox   Running   tcp://192.168.99.101:2376           v1.12.1   
dev3   -        virtualbox   Running   tcp://192.168.99.102:2376           v1.12.1      
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we can begin launching our consul service on each node.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker run -d --net=host \
 -e &#39;CONSUL_LOCAL_CONFIG={&amp;quot;skip_leave_on_interrupt&amp;quot;: true}&#39; \
 --name=consul \
 consul agent -server \
 -bind=192.168.99.100 \
 -retry-join=192.168.99.101 \
 -bootstrap-expect=3 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For an explanation of the options when running the agent, I highly encourage you to look over the &lt;a href=&#34;https://www.consul.io/docs/agent/options.html&#34;&gt;consul documentation&lt;/a&gt;. The team over at Hashicorp has done a really great job maintaining their docs.&lt;/p&gt;

&lt;p&gt;When supplying the retry-join option, you can enter the first IP-address of the node, or another node. Meaning, you can either have all nodes point to the first node, or have each one point to another node, either method seems to work fine.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note: If this is not the case someone please comment on accepted best practice.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Understanding consensus and Raft may not be necessary for this small walk-through, but if you are interested. I will do my best to explain it in another post, meanwhile, this is a great visualization and explanation of Raft consensus.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://thesecretlivesofdata.com/raft/&#34;&gt;The Secret Lives of Data - Raft&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Once you have launched Consul on each node, let&amp;rsquo;s check the logs from the first consul container we launched. We should see our leader elected.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ eval $(docker-machine env dev1)
$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS               NAMES
f594e58e3cad        consul              &amp;quot;docker-entrypoint.sh&amp;quot;   4 minutes ago       Up 4 minutes                            backstabbing_brown
$ docker logs --tail 20 f594
    2016/09/10 19:03:38 [ERR] agent: coordinate update error: No cluster leader
    2016/09/10 19:03:52 [ERR] agent: failed to sync remote state: No cluster leader
    2016/09/10 19:04:02 [ERR] agent: coordinate update error: No cluster leader
    2016/09/10 19:04:17 [ERR] agent: failed to sync remote state: No cluster leader
    2016/09/10 19:04:29 [ERR] agent: coordinate update error: No cluster leader
    2016/09/10 19:04:30 [INFO] serf: EventMemberJoin: dev3 192.168.99.102
    2016/09/10 19:04:30 [INFO] consul: adding LAN server dev3 (Addr: 192.168.99.102:8300) (DC: dc1)
    2016/09/10 19:04:30 [INFO] consul: Attempting bootstrap with nodes: [192.168.99.100:8300 192.168.99.101:8300 192.168.99.102:8300]
    2016/09/10 19:04:31 [WARN] raft: Heartbeat timeout reached, starting election
    2016/09/10 19:04:31 [INFO] raft: Node at 192.168.99.100:8300 [Candidate] entering Candidate state
    2016/09/10 19:04:31 [INFO] raft: Election won. Tally: 2
    2016/09/10 19:04:31 [INFO] raft: Node at 192.168.99.100:8300 [Leader] entering Leader state
    2016/09/10 19:04:31 [INFO] consul: cluster leadership acquired
    2016/09/10 19:04:31 [INFO] consul: New leader elected: dev1
    2016/09/10 19:04:31 [INFO] raft: pipelining replication to peer 192.168.99.102:8300
    2016/09/10 19:04:31 [INFO] raft: pipelining replication to peer 192.168.99.101:8300
    2016/09/10 19:04:31 [INFO] consul: member &#39;dev1&#39; joined, marking health alive
    2016/09/10 19:04:31 [INFO] consul: member &#39;dev2&#39; joined, marking health alive
    2016/09/10 19:04:31 [INFO] consul: member &#39;dev3&#39; joined, marking health alive
    2016/09/10 19:04:32 [INFO] agent: Synced service &#39;consul&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s test our consul installation first by logging into a node and attempting to query the API for some information.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker-machine ssh dev1
                        ##         .
                  ## ## ##        ==
               ## ## ## ## ##    ===
           /&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;\___/ ===
      ~~~ {~~ ~~~~ ~~~ ~~~~ ~~~ ~ /  ===- ~~~
           \______ o           __/
             \    \         __/
              \____\_______/
 _                 _   ____     _            _
| |__   ___   ___ | |_|___ \ __| | ___   ___| | _____ _ __
| &#39;_ \ / _ \ / _ \| __| __) / _` |/ _ \ / __| |/ / _ \ &#39;__|
| |_) | (_) | (_) | |_ / __/ (_| | (_) | (__|   &amp;lt;  __/ |
|_.__/ \___/ \___/ \__|_____\__,_|\___/ \___|_|\_\___|_|
Boot2Docker version 1.12.1, build HEAD : ef7d0b4 - Thu Aug 18 21:18:06 UTC 2016
Docker version 1.12.1, build 23cf638
$ curl localhost:8500/v1/catalog/nodes
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After the curl you should be greeted with some output similar to this:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-JSON&#34;&gt;[{&amp;quot;Node&amp;quot;:&amp;quot;dev1&amp;quot;,&amp;quot;Address&amp;quot;:&amp;quot;192.168.99.100&amp;quot;,&amp;quot;TaggedAddresses&amp;quot;:{&amp;quot;wan&amp;quot;:&amp;quot;192.168.99.100&amp;quot;},&amp;quot;CreateIndex&amp;quot;:3,&amp;quot;ModifyIndex&amp;quot;:6},{&amp;quot;Node&amp;quot;:&amp;quot;dev2&amp;quot;,&amp;quot;Address&amp;quot;:&amp;quot;192.168.99.101&amp;quot;,&amp;quot;TaggedAddresses&amp;quot;:{&amp;quot;wan&amp;quot;:&amp;quot;192.168.99.101&amp;quot;},&amp;quot;CreateIndex&amp;quot;:4,&amp;quot;ModifyIndex&amp;quot;:7},{&amp;quot;Node&amp;quot;:&amp;quot;dev3&amp;quot;,&amp;quot;Address&amp;quot;:&amp;quot;192.168.99.102&amp;quot;,&amp;quot;TaggedAddresses&amp;quot;:{&amp;quot;wan&amp;quot;:&amp;quot;192.168.99.102&amp;quot;},&amp;quot;CreateIndex&amp;quot;:5,&amp;quot;ModifyIndex&amp;quot;:8}]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can go ahead and proceed to launch Registrator on each node now.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ eval $(docker-machine env dev1)
$ docker run -d --name=registrator --net=host --volume=/var/run/docker.sock:/tmp/docker.sock gliderlabs/registrator consul://localhost:8500
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And repeat for all three nodes. Registrator automatically registers and deregisters services for any Docker container by inspecting containers as they come online. Notice we are mounting the Docker socket in our Registrator container, this is how we are able to see transactions going through docker.&lt;/p&gt;

&lt;p&gt;Now that Registrator and Consul are running on all nodes, let&amp;rsquo;s launch a new service&amp;hellip;&lt;/p&gt;

&lt;p&gt;How about Redis?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ eval $(docker-machine env dev2)
$ docker run -d -p 6379:6379 --name redis redis
$ docker-machine ssh dev3
$ curl localhost:8500/v1/catalog/services
{&amp;quot;consul&amp;quot;:[],&amp;quot;redis&amp;quot;:[]}
$ curl localhost:8500/v1/catalog/service/redis
[{&amp;quot;Node&amp;quot;:&amp;quot;dev2&amp;quot;,&amp;quot;Address&amp;quot;:&amp;quot;192.168.99.101&amp;quot;,&amp;quot;ServiceID&amp;quot;:&amp;quot;dev2:redis:6379&amp;quot;,&amp;quot;ServiceName&amp;quot;:&amp;quot;redis&amp;quot;,&amp;quot;ServiceTags&amp;quot;:[],&amp;quot;ServiceAddress&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;ServicePort&amp;quot;:6379,&amp;quot;ServiceEnableTagOverride&amp;quot;:false,&amp;quot;CreateIndex&amp;quot;:93,&amp;quot;ModifyIndex&amp;quot;:93}]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Great! Now we know information about where Redis is running and the ports that it is listening on. The documentation on Registrator is well maintained and is invaluable when working with this setup. Even though I was able to stand up a Redis instance and retrieve the service information, I still need to supply health checks and other information.&lt;/p&gt;

&lt;p&gt;Say we were standing up Nginx. We want to declare a health check at the time the container is launched. We can tell Registrator about our service at the time of launch using environment variables. Like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker run -d --net=host -e SERVICE_CHECK_SCRIPT=&amp;quot;curl --silent --fail localhost&amp;quot; -e SERVICE_TAGS=&amp;quot;urlprefix-/nginx&amp;quot; -p 8081:80 -p 44300:443 nginx:1.10
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If we check our consul entries we can see that there is a health now for Nginx&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl localhost:8500/v1/health/service/nginx-80
[{&amp;quot;Node&amp;quot;:{&amp;quot;Node&amp;quot;:&amp;quot;dev3&amp;quot;,&amp;quot;Address&amp;quot;:&amp;quot;192.168.99.102&amp;quot;,&amp;quot;TaggedAddresses&amp;quot;:{&amp;quot;wan&amp;quot;:&amp;quot;192.168.99.102&amp;quot;},&amp;quot;CreateIndex&amp;quot;:5,&amp;quot;ModifyIndex&amp;quot;:145},&amp;quot;Service&amp;quot;:{&amp;quot;ID&amp;quot;:&amp;quot;dev3:nginx:80&amp;quot;,&amp;quot;Service&amp;quot;:&amp;quot;nginx-80&amp;quot;,&amp;quot;Tags&amp;quot;:[&amp;quot;urlprefix-/nginx&amp;quot;],&amp;quot;Address&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;Port&amp;quot;:8081,&amp;quot;EnableTagOverride&amp;quot;:false,&amp;quot;CreateIndex&amp;quot;:145,&amp;quot;ModifyIndex&amp;quot;:145},&amp;quot;Checks&amp;quot;:[{&amp;quot;Node&amp;quot;:&amp;quot;dev3&amp;quot;,&amp;quot;CheckID&amp;quot;:&amp;quot;serfHealth&amp;quot;,&amp;quot;Name&amp;quot;:&amp;quot;Serf Health Status&amp;quot;,&amp;quot;Status&amp;quot;:&amp;quot;passing&amp;quot;,&amp;quot;Notes&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;Output&amp;quot;:&amp;quot;Agent alive and reachable&amp;quot;,&amp;quot;ServiceID&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;ServiceName&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;CreateIndex&amp;quot;:5,&amp;quot;ModifyIndex&amp;quot;:5},{&amp;quot;Node&amp;quot;:&amp;quot;dev3&amp;quot;,&amp;quot;CheckID&amp;quot;:&amp;quot;service:dev3:nginx:80&amp;quot;,&amp;quot;Name&amp;quot;:&amp;quot;Service &#39;nginx-80&#39; check&amp;quot;,&amp;quot;Status&amp;quot;:&amp;quot;critical&amp;quot;,&amp;quot;Notes&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;Output&amp;quot;:&amp;quot;&amp;quot;,&amp;quot;ServiceID&amp;quot;:&amp;quot;dev3:nginx:80&amp;quot;,&amp;quot;ServiceName&amp;quot;:&amp;quot;nginx-80&amp;quot;,&amp;quot;CreateIndex&amp;quot;:145,&amp;quot;ModifyIndex&amp;quot;:145}]}]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It really can be that easy. There is a lot happening under the hood, but at its core, service discovery really can be that easy. Now when configuring my app, I can make some calls to a Rest API about service data I need for inside my application. I will try to follow up with another post on using &lt;a href=&#34;https://github.com/eBay/fabio&#34;&gt;Fabio&lt;/a&gt; for load-balancing in this set-up.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Benchmarking Amazon&#39;s Aurora</title>
      <link>https://callmeradical.com/post/aurora-benchmark/</link>
      <pubDate>Wed, 07 Sep 2016 11:57:11 -0400</pubDate>
      
      <guid>https://callmeradical.com/post/aurora-benchmark/</guid>
      <description>&lt;p&gt;I saw this study by the folks over at &lt;a href=&#34;https://cloudplatform.googleblog.com/2016/08/Cloud-SQL-Second-Generation-performance-and-feature-deep-dive.html&#34;&gt;Google and their 2nd Generation Cloud SQL&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The results they posted didn&amp;rsquo;t exactly mirror what I saw when running the benchmarks for myself.
You can get the raw data here @ &lt;a href=&#34;https://github.com/2ndWatch/aurora_benchmark&#34;&gt;Github.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Everything was stood up using Terraform, the benchmark tests were conducted using Sysbench, and all data was plotted using R.&lt;/p&gt;

&lt;p&gt;Since we didn&amp;rsquo;t have access to Google&amp;rsquo;s original data, we provided some overlays in the post as an easy visual comparison. However the data used to produce all of those graphs as well as additional data is in the repo.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://2ndwatch.com/blog/benchmarking-amazon-aurora/&#34;&gt;Read More @ 2ndwatch.com&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Free advice from a Terraform user</title>
      <link>https://callmeradical.com/post/free-advice-from-a-terraform-user/</link>
      <pubDate>Thu, 31 Mar 2016 20:40:23 -0400</pubDate>
      
      <guid>https://callmeradical.com/post/free-advice-from-a-terraform-user/</guid>
      <description>&lt;p&gt;Firstly a huge thank you goes out to &lt;a href=&#34;https://twitter.com/mipsytipsy?lang=en&#34;&gt;@mipsytipsy&lt;/a&gt; for this awesome post mortem on what appears to be or what could have been one of the worst outages of her career.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Some context: our terraform config had been pretty stable for a few weeks.  After I got it set up, I hardly ever needed to touch it.  This was an explicit goal of mine.  (I have strong feelings about delegation of authority and not using your orchestration layer for configuration, but that’s for another day.)&lt;/p&gt;

&lt;p&gt;And then one day I decided to test drive Aurora in staging, and everything exploded.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;http://charity.wtf/2016/03/30/terraform-vpc-and-why-you-want-a-tfstate-file-per-env/&#34;&gt;Read more @ Charity.wtf&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Container best practices from RedHat</title>
      <link>https://callmeradical.com/post/container-best-practices-from-redhat/</link>
      <pubDate>Thu, 31 Mar 2016 16:03:39 -0400</pubDate>
      
      <guid>https://callmeradical.com/post/container-best-practices-from-redhat/</guid>
      <description>&lt;p&gt;I came across this post in a slack channel earlier today and thought it was some pretty sound advice for those starting out in the container eco system.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;First: Containers are immutable – The OS, library versions, configurations, folders, and application are all wrapped inside the container. You guarantee that the same image that was tested in QA will reach the production environment with the same behaviour.&lt;/p&gt;

&lt;p&gt;Second: Containers are lightweight – The memory footprint of a container is small. Instead of hundreds or thousands of MBs, the container will only allocate the memory for the main process.&lt;/p&gt;

&lt;p&gt;Third: Containers are fast – You can start a container as fast as a typical linux process takes to start. Instead of minutes, you can start a new container in few seconds.&lt;/p&gt;

&lt;p&gt;However, many users are still treating containers just like typical virtual machines and forget that containers have an important characteristic: Containers are disposable.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;http://developerblog.redhat.com/2016/02/24/10-things-to-avoid-in-docker-containers/&#34;&gt;Read More Here @ Red Hat&amp;rsquo;s Developer Blog&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multitasking? You want to talk about multitasking?</title>
      <link>https://callmeradical.com/post/multitasking-you-want-to-talk-about-multitasking/</link>
      <pubDate>Tue, 08 Mar 2016 06:32:21 -0400</pubDate>
      
      <guid>https://callmeradical.com/post/multitasking-you-want-to-talk-about-multitasking/</guid>
      <description>&lt;p&gt;Reading is definitely a passion for me. I love reading every chance I get. So few books have stuck with me or have become even a flavor of the week that I feel like I have to recommend Greg McKeown&amp;rsquo;s Essentialism again.&lt;/p&gt;

&lt;p&gt;I came by another post, not long after reading Greg&amp;rsquo;s book, talking about priorities and the nonsense it creates.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The Myth of Multitasking
Yes, we are capable of doing two things at the same time. It is possible, for example, to watch TV while cooking dinner or to answer an email while talking on the phone.&lt;/p&gt;

&lt;p&gt;What is impossible, however, is concentrating on two tasks at once. Multitasking forces your brain to switch back and forth very quickly from one task to another.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Check out the whole post below for a good read.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://jamesclear.com/multitasking-myth&#34;&gt;http://jamesclear.com/multitasking-myth&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>SQL Server on Linux?</title>
      <link>https://callmeradical.com/post/sql-server-on-linux/</link>
      <pubDate>Tue, 08 Mar 2016 05:20:05 -0400</pubDate>
      
      <guid>https://callmeradical.com/post/sql-server-on-linux/</guid>
      <description>&lt;p&gt;Yeah you saw that right. This new Microsoft confuses me almost on a daily basis. Part of me thinks that this is awesome, and then another part yells at me for thinking it is awesome.&lt;/p&gt;

&lt;p&gt;I think it is great that Microsoft is looking to make good with the open-source community. They are the second largest contributor to Docker outside of Docker, and now this push to put SQL Server on Linux is yet another attempt to break bread.&lt;/p&gt;

&lt;p&gt;I think it is great that they are moving in this direction. I also think it is somewhat sad that they are trying to re-platform one of their products to work on something outside of their own platform. I can only assume that this is a direct lesson learned from SQL on Azure and at scale.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Today I’m excited to announce our plans to bring SQL Server to Linux as well. This will enable SQL Server to deliver a consistent data platform across Windows Server and Linux, as well as on-premises and cloud. We are bringing the core relational database capabilities to preview today, and are targeting availability in mid-2017.&lt;/p&gt;

&lt;p&gt;SQL Server on Linux will provide customers with even more flexibility in their data solution. One with mission-critical performance, industry-leading TCO, best-in-class security, and hybrid cloud innovations – like Stretch Database which lets customers access their data on-premises and in the cloud whenever they want at low cost – all built in.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Follow The Yellow Brick Road to learn more about this.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://blogs.microsoft.com/blog/2016/03/07/announcing-sql-server-on-linux/&#34;&gt;https://blogs.microsoft.com/blog/2016/03/07/announcing-sql-server-on-linux/&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>About</title>
      <link>https://callmeradical.com/page/about/</link>
      <pubDate>Sat, 27 Feb 2016 19:33:58 -0400</pubDate>
      
      <guid>https://callmeradical.com/page/about/</guid>
      <description>&lt;p&gt;I also have other responsibilities.
As I have grown older my focus has shifted to raising my three daughters with my wife Brandi.
I attend meetups around the Philadelphia area on occasion and can be found in attendance at a variety of conferences.
If you see me around, please don&amp;rsquo;t hesitate to say hello.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://callmeradical.com/content/images/2016/02/10625083_10153071759151835_3799002716622385188_n.jpg&#34; alt=&#34;alt&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>You cannot overestimate the unimportance of practically everything.</title>
      <link>https://callmeradical.com/post/you-cannot-overestimate-the-unimportance-of-practically-everything/</link>
      <pubDate>Thu, 28 Jan 2016 03:52:59 -0400</pubDate>
      
      <guid>https://callmeradical.com/post/you-cannot-overestimate-the-unimportance-of-practically-everything/</guid>
      <description>&lt;p&gt;I don&amp;rsquo;t typically subscribe to books about decision-making or &amp;ldquo;life hacking&amp;rdquo; or even time management.&lt;/p&gt;

&lt;p&gt;I just finished my second read of Essentialism by Greg McKeown. I read through it the first time, and I was skeptical. After my second read, I can say I am a believer.&lt;/p&gt;

&lt;p&gt;I can&amp;rsquo;t recommend this book enough. I have had trouble divorcing myself from work for a while. I would always be the guy saying;&lt;/p&gt;

&lt;p&gt;&amp;ldquo;Let me just finish this one last thing.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;p&gt;&amp;ldquo;I just have to send this e-mail.&amp;rdquo;&lt;/p&gt;

&lt;p&gt;Essentialism has helped me tune out the noise and focus what really matters.&lt;/p&gt;

&lt;p&gt;That last e-mail can wait, and there will always be one last thing.&lt;/p&gt;

&lt;p&gt;Check it out.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.amazon.com/Essentialism-Disciplined-Pursuit-Greg-McKeown/dp/0804137382/ref=sr_1_1?s=books&amp;amp;ie=UTF8&amp;amp;qid=1453951553&amp;amp;sr=1-1&amp;amp;keywords=essentialism+the+disciplined+pursuit+of+less&#34;&gt;Essentialism, buy it on Amazon&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://callmeradical.com/content/images/2016/01/essentialism.jpg&#34; height=&#34;600&#34;/&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lambda, Docker/ECS, and S3... sitting in a tree.</title>
      <link>https://callmeradical.com/post/aws-techconnect-seattle/</link>
      <pubDate>Wed, 28 Oct 2015 00:59:36 -0400</pubDate>
      
      <guid>https://callmeradical.com/post/aws-techconnect-seattle/</guid>
      <description>&lt;p&gt;To go along with a talk I am doing this week, I created a demo project to reinforce the idea behind ephemeral architecture and infrastructure as code.&lt;/p&gt;

&lt;p&gt;We create two S3 buckets for the purpose of intake and another to serve out a static site we will be generating using ECS.&lt;/p&gt;

&lt;p&gt;The first bucket is a place to drop photos which then triggers a lambda function, we will call this photo_bucket.&lt;/p&gt;

&lt;p&gt;This piece of nodejs code will be the lambda we use to launch our ECS task:&lt;/p&gt;

&lt;p&gt;```prettyprint lang-nodejs
console.log(&amp;lsquo;Loading function&amp;rsquo;);
var aws = require(&amp;lsquo;aws-sdk&amp;rsquo;);
exports.handler = function(event, context) {
  var ecs = new aws.ECS();
  var params = {
    taskDefinition: &amp;lsquo;arn:account:::ecstask&amp;rsquo;,
    count: 1,
    startedBy: &amp;lsquo;lambda&amp;rsquo;
  };
ecs.runTask(params, function(err, data) {
  if (err) console.log(err, err.stack);
  else    { console.log(data); context.succeed(&amp;lsquo;yew!&amp;rsquo;);}
  });
};&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 
To launch the static site I decided on Jekyll, which is the basis for a lot of Github hosted blogs, to generate a static site. I forked the code-base for Jekyll to my own repository and containerized it. Here is the Dockerfile:

```prettyprint lang-bash
FROM gliderlabs/alpine

RUN apk update
RUN apk upgrade

RUN apk add \
    git \
    imagemagick-dev \
    ruby-dev \
    build-base \
    libffi-dev \
    nodejs \
    python

RUN curl -sq &amp;quot;https://s3.amazonaws.com/aws-cli/awscli-bundle.zip&amp;quot; -o &amp;quot;awscli-bundle.zip&amp;quot;
RUN unzip awscli-bundle.zip
RUN ./awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws

RUN git clone https://github.com/callmeradical/aws_techconnect /src

WORKDIR /src

RUN chmod +x scripts/sync.sh

RUN /usr/bin/gem install bundler

RUN bundle install

RUN bundle exec jekyll build

ENTRYPOINT /usr/bin/ruby scripts/set_env.rb &amp;amp;&amp;amp; source creds &amp;amp;&amp;amp; ./scripts/sync.sh 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is some other stuff in here that I added to the repository since we are running on AWS. Namely a small script to grab credentials from the EC2 metadata of the docker host so we don&amp;rsquo;t have to worry about storing credentials in the container or rebuilding it.&lt;/p&gt;

&lt;p&gt;``&lt;code&gt;prettyprint lang-ruby
require &#39;json&#39;
url = &#39;-sq http://169.254.169.254/latest/meta-data/iam/security-credentials/&#39;
role =&lt;/code&gt;curl #{url}&lt;code&gt;
doc =&lt;/code&gt;curl #{url}/#{role}/`&lt;/p&gt;

&lt;p&gt;creds = JSON.parse(doc)
File.open(&amp;lsquo;creds&amp;rsquo;, &amp;lsquo;w&amp;rsquo;) do |file|
  file.write(&amp;ldquo;export AWS_KEY=\&amp;ldquo;#{creds[&amp;lsquo;AccessKeyId&amp;rsquo;]}\&amp;rdquo;\n&amp;rdquo;)
  file.write(&amp;ldquo;export AWS_SECRET=\&amp;ldquo;#{creds[&amp;lsquo;SecretAccessKey&amp;rsquo;]}\&amp;rdquo;\n&amp;rdquo;)
  file.write(&amp;ldquo;export BUCKET=\&amp;ldquo;s3://photo_bucket\&amp;rdquo;\n&amp;rdquo;)
  file.write(&amp;ldquo;export SITE=\&amp;ldquo;s3://demo_site\&amp;ldquo;&amp;rdquo;)
end&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
We use the credentials as environment variables and perform a sync from S3 to the container, build the site, and ship it.

```prettyprint lang-bash
aws s3 sync $BUCKET photos/
bundle exec jekyll build
aws s3 sync _site $SITE
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This isn&amp;rsquo;t the best way to do this but it helps illustrate an easy use case or model for performing batch processing.&lt;/p&gt;

&lt;p&gt;If you want to stand this up yourself, the cloudformation templates are located in the &lt;a href=&#34;https://github.com/callmeradical/aws_techconnect&#34;&gt;GitHub Repo&lt;/a&gt; under the scripts folder.&lt;/p&gt;

&lt;p&gt;Note: I didn&amp;rsquo;t externalize the bucket names, so you may have to change the names of the buckets in the template and the set_env.rb file.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tetris... err... Getting Started with Kubernetes</title>
      <link>https://callmeradical.com/post/getting-started-with-k8s/</link>
      <pubDate>Wed, 30 Sep 2015 02:39:08 -0400</pubDate>
      
      <guid>https://callmeradical.com/post/getting-started-with-k8s/</guid>
      <description>&lt;p&gt;After watching &lt;a href=&#34;https://twitter.com/kelseyhightower&#34;&gt;@kelseyhightower&amp;rsquo;s&lt;/a&gt; speech at &lt;a href=&#34;https://www.youtube.com/watch?v=pozC9rBvAIs&#34;&gt;Strangeloop 2015.&lt;/a&gt; I was really impressed at the ease of instruction and demonstration he showed. I had not played with Kubernetes aside from using the kube-up.sh script in the github repo with the EC2 provider.&lt;/p&gt;

&lt;p&gt;He starts off the talk by saying:
&amp;gt; How would you design your infrastructure if you could never login?&lt;/p&gt;

&lt;p&gt;I have worked with clients and have said these exact words. It immediately grabbed my attention.&lt;/p&gt;

&lt;p&gt;Kelsey goes on to talk briefly about abstraction, containers,a sample application in Golang, and begins demonstrating application deployment to Kubernetes.&lt;/p&gt;

&lt;p&gt;After walking through the basic workings of Kubernetes, he provides an awesome illustration of resource utilization using Kubernetes, using Tetris.&lt;/p&gt;

&lt;p&gt;Overall this is a great introduction to how Kubernetes works and the problems it aims at solving. Much to Hightower&amp;rsquo;s credit, he also says what Kubernetes won&amp;rsquo;t solve, if not in a kind of tongue and cheek way.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If your in the enterprise and all your stuff is written in Java, and you have to deploy to Oracle&amp;hellip; I have to be honest, there is nothing Kubernetes can do for you if you have that particular setup.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now obviously he doesn&amp;rsquo;t mean that, but it does paint a picture of when to use the tool and when not to.&lt;/p&gt;

&lt;p&gt;Overall if you haven&amp;rsquo;t had a chance to play with Kubernetes or you don&amp;rsquo;t know what all the hype is about. Check out his talk at Strangeloop. Head on over to &lt;a href=&#34;http://kubernetes.io&#34;&gt;Kubernetes.io&lt;/a&gt; and look through the getting started guide. They have providers for most of the major IaaS; AWS, GCE, Azure, and even Vagrant.&lt;/p&gt;

&lt;p&gt;I am going to be working on getting started with AWS. The supported method, while if you have read my previous post I am not a fan of.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ export KUBERNETES_PROVIDER=aws; curl -sS https://get.k8s.io | bash
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Though supported, I opted to not go this route and clone the repo here &lt;a href=&#34;https://github.com/kubernetes/kubernetes&#34;&gt;kubernetes @ github&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ git clone https://github.com/kubernetes/kubernetes.git
$ cd kubernetes
$ export KUBERNETES_PROVIDER=aws
$ ./cluster/kube-up.sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will launch a combination of bash, cloudformation, salt and some other potpourri. After about 5 minutes or so you will be greeted with this output :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Kubernetes cluster is running.  The master is running at:

https://XX.XX.XX.XX


The user name and password to use is located in ...
... calling validate-cluster
Found 4 nodes.
      
Elasticsearch is running at https://XX.XX.XX.XX/api/v1beta3/proxy/namespaces/default/services/elasticsearch-logging
Kibana is running at https://XX.XX.XX.XX/api/v1beta3/proxy/namespaces/default/services/kibana-logging
KubeDNS is running at https://XX.XX.XX.XX/api/v1beta3/proxy/namespaces/default/services/kube-dns
Grafana is running at https://XX.XX.XX.XX/api/v1beta3/proxy/namespaces/default/services/monitoring-grafana
 is running at https://XX.XX.XX.XX/api/v1beta3/proxy/namespaces/default/services/monitoring-heapster
influxGrafana is running at https://XX.XX.XX.XX/api/v1beta3/proxy/namespaces/default/services/monitoring-influxdb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At this point if you cloned the repo, you can now navigate to the examples folder and begin playing around with creating pods, services, and exposing them.  For a little more direction I highly recommend &lt;a href=&#34;http://kubernetes.io/v1.0/examples/guestbook/&#34;&gt;this walk through&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Eight Docker Development Patterns</title>
      <link>https://callmeradical.com/post/eight-docker-dev-patterns/</link>
      <pubDate>Tue, 29 Sep 2015 02:36:55 -0400</pubDate>
      
      <guid>https://callmeradical.com/post/eight-docker-dev-patterns/</guid>
      <description>&lt;p&gt;This was a post I had stashed away a while ago by &lt;a href=&#34;http://www.hokstad.com&#34;&gt;Vidar Hokstad&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;He goes into some of the uses he has been seeing/using docker for. I have used some of these and I am sure there are even more development patterns out there now. The one I am most  interested in is the &amp;lsquo;installer&amp;rsquo; container as he calls it.&lt;/p&gt;

&lt;p&gt;There are so many installers that come in the form of&amp;hellip;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ curl http://what.is.this.bullsh.it | sudo sh
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I can&amp;rsquo;t stand it, I know I can&amp;rsquo;t be alone on this.
&lt;!-- more --&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;The Installation Container
This is not my own, but really deserves a mention. The excellent nsenter and docker-enter tools comes with an installation option that is a nice step forward from the popular but terrifying &amp;ldquo;curl [some url you have no control over] | bash&amp;rdquo; pattern. It does this by providing a Docker container that implements the &amp;ldquo;Build Container&amp;rdquo; pattern from above, but goes one step further. It deserves a look.&lt;sup&gt;1&lt;/sup&gt;
&lt;div align=right&gt;~Vidar Hokstad
&lt;/div&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;This post is a little old and while I don&amp;rsquo;t necessarily agree with the &amp;lsquo;mount&amp;rsquo; my home folder in this container too frequently, I think there are some good uses for docker in there (as if you needed anymore).&lt;/p&gt;

&lt;p&gt;&lt;sup&gt;1&lt;/sup&gt;Vidar Hokstad - &lt;a href=&#34;http://www.hokstad.com/docker/patterns&#34;&gt;Eight Docker Development Patterns&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Working with octopress... in a container.</title>
      <link>https://callmeradical.com/post/working-with-octopress-dot-dot-dot-in-a-container/</link>
      <pubDate>Fri, 25 Sep 2015 05:33:56 -0400</pubDate>
      
      <guid>https://callmeradical.com/post/working-with-octopress-dot-dot-dot-in-a-container/</guid>
      <description>&lt;p&gt;So I have been on a bit of a kick with Docker. I have been in Boston talking
about it, giving webinars on it, and using it just about everywhere in every
which way I can.&lt;/p&gt;

&lt;p&gt;One of the first things I realized is that I hate installing dependencies on
all of my things. Installing ruby, git, gcc, and not to mention all the gems
that I need to run.&lt;/p&gt;

&lt;p&gt;I decided the first thing I wanted to do was make it easier to write my blog
(which is already ridiculously easy, thanks Github!), I also just wanted to
see if I could run my blog outside of Github pages if the need arises.
&lt;!-- more --&gt;
So here we go.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;Octopress&#34;&gt;www.octopress.org&lt;/a&gt; is/was a blogging framework largely based on
&lt;a href=&#34;Jekyll&#34;&gt;www.jekyllrb.com&lt;/a&gt;. Since then it has been replaced with a variety
of Gems.&lt;/p&gt;

&lt;p&gt;Dockerfile&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM debian:8.1

RUN apt-get update
RUN apt-get install -y \
  git \
  ruby \
  ruby-dev \
  rubygems \
  build-essential \
  nodejs \
  python

RUN git clone https://github.com/callmeradical/callmeradical.github.io
WORKDIR callmeradical.github.io

RUN git checkout source
RUN /bin/bash -l -c &amp;quot;gem install bundler&amp;quot;
RUN /bin/bash -l -c &amp;quot;bundle install&amp;quot;

EXPOSE 4000

RUN apt-get autoremove -y
RUN useradd -ms /bin/bash lars
USER lars
ENTRYPOINT [&amp;quot;/usr/local/bin/rake&amp;quot;, &amp;quot;preview&amp;quot; ]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can look at this a little closer for those that have never written a Dockerfile before.
The very first line:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;FROM debian:8.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Tells me that I am inheritting from another container. All the configuration that went into
making that container can be viewed on &lt;a href=&#34;Docker Hub&#34;&gt;hub.docker.com&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So that will get me to a base install of the OS. The next few lines are pretty self
explanatory. I am installing packages necessary for the my application to run.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RUN apt-get update
RUN apt-get install -y \
  git \
  ruby \
  ruby-dev \
  rubygems \
  build-essential \
  nodejs \
  python


&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now we are ready to clone in our project:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RUN git clone https://github.com/callmeradical/callmeradical.github.io
WORKDIR callmeradical.github.io

RUN git checkout source
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I am using github pages to deploy my blog and it builds &amp;lsquo;master&amp;rsquo; from &amp;lsquo;source&amp;rsquo; so
I check out the source branch and install my gems..&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;RUN /bin/bash -l -c &amp;quot;gem install bundler&amp;quot;
RUN /bin/bash -l -c &amp;quot;bundle install&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;EXPOSE Docker that the container will listen on the specified network ports at runtime.
Docker uses this information to interconnect containers using links, which is helpful if
we decide we want to run our blog in a more traditional way fronted by Nginx or apache.&lt;/p&gt;

&lt;p&gt;Finally I add a user with the same username as my local machine, this is pretty important.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;EXPOSE 4000

RUN useradd -ms /bin/bash lars
USER lars
ENTRYPOINT [&amp;quot;/usr/local/bin/rake&amp;quot;, &amp;quot;preview&amp;quot; ]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now I add this file to my octopress blog repo and I can now build my container:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker build --rm=true -t callmeradical/blog:latest .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That might take a little bit to install the packages and deps, but once that is complete
I can now run my blog locally while editing/working on posts.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -i -t \
-v ~/src/1_docker_callmeradical.github.io:/callmeradical.github.io \ 
-p 80:4000 \
-d --name blog callmeradical/blog              
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This might look unusual at first but there is a reason why I am running it this way.
I can perform all my edits locally and the preview will continue to regenerate the view
for me. Combine that my transparent terminal, I can see whats happening as I am posting.&lt;/p&gt;

&lt;p&gt;Now if I have to interact in a different way to say do a deployment, or generate a new
post, I can just use&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker exec -ti &amp;lt;command&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>It&#39;s that time again...</title>
      <link>https://callmeradical.com/post/its-that-time-again-dot-dot-dot/</link>
      <pubDate>Thu, 24 Sep 2015 16:07:36 -0400</pubDate>
      
      <guid>https://callmeradical.com/post/its-that-time-again-dot-dot-dot/</guid>
      <description>&lt;p&gt;Well it is that time again. AWS re:Invent is right around the corner and I will
once again be making the trek to beautiful Las Vegas. I am looking forward to
seeing some familiar faces and even more excited to see what new service
offerings will be unveiled.&lt;/p&gt;

&lt;p&gt;Plenty of people from &lt;a href=&#34;https://2ndwatch.com&#34;&gt;2ndWatch&lt;/a&gt; will be there @ booth # 626
so be sure to swing on by and chat for a bit.&lt;/p&gt;

&lt;p&gt;I will be live-tweeting and blogging from re:Invent during the keynotes and will
be providing some commentary around some of the new products from various vendors.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>